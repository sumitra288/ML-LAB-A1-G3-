{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/gist/sumitra288/eeaa2d2c7d1ccfa8243bc8824386c20b/experiment4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import defaultdict\n",
        "import re"
      ],
      "metadata": {
        "id": "I-pcbNcGTjRy"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultinomialNaiveBayes:\n",
        "    def __init__(self, alpha=1.0):\n",
        "        self.alpha = alpha\n",
        "        self.class_priors = {}\n",
        "        self.word_probs = {}\n",
        "        self.vocabulary = set()\n",
        "        self.classes = []\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.classes = np.unique(y)\n",
        "        n_samples = X.shape[0]\n",
        "        n_features = X.shape[1]\n",
        "\n",
        "        for class_label in self.classes:\n",
        "            class_count = np.sum(y == class_label)\n",
        "            self.class_priors[class_label] = class_count / n_samples\n",
        "\n",
        "        self.word_probs = {}\n",
        "        for class_label in self.classes:\n",
        "            class_mask = (y == class_label)\n",
        "            class_docs = X[class_mask]\n",
        "\n",
        "            word_counts = np.sum(class_docs, axis=0)\n",
        "            total_words = np.sum(word_counts)\n",
        "\n",
        "            word_probs = (word_counts + self.alpha) / (total_words + self.alpha * n_features)\n",
        "            self.word_probs[class_label] = word_probs\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        n_samples = X.shape[0]\n",
        "        n_classes = len(self.classes)\n",
        "        probabilities = np.zeros((n_samples, n_classes))\n",
        "\n",
        "        for i, class_label in enumerate(self.classes):\n",
        "            log_prob = np.log(self.class_priors[class_label])\n",
        "            word_log_probs = np.log(self.word_probs[class_label])\n",
        "            doc_log_probs = X.dot(word_log_probs)\n",
        "            probabilities[:, i] = log_prob + doc_log_probs\n",
        "\n",
        "        probabilities = probabilities - np.max(probabilities, axis=1, keepdims=True)\n",
        "        probabilities = np.exp(probabilities)\n",
        "        probabilities = probabilities / np.sum(probabilities, axis=1, keepdims=True)\n",
        "\n",
        "        return probabilities\n",
        "\n",
        "    def predict(self, X):\n",
        "        probabilities = self.predict_proba(X)\n",
        "        return self.classes[np.argmax(probabilities, axis=1)]"
      ],
      "metadata": {
        "id": "ljrVJI8sWEW3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_realistic_spam_dataset():\n",
        "    spam_messages = [\n",
        "        \"free money now call immediately urgent offer limited time\",\n",
        "        \"win big prizes click here now exclusive deal today only\",\n",
        "        \"urgent business proposal money transfer prince nigeria help needed\",\n",
        "        \"congratulations you won lottery claim prize now click link\",\n",
        "        \"limited time offer act now save money huge discount\",\n",
        "        \"call now free consultation prize money winner selected today\",\n",
        "        \"click here for instant money rewards cash prize waiting\",\n",
        "        \"urgent reply needed money waiting transfer funds immediately\",\n",
        "        \"exclusive offer limited time big savings discount percentage off\",\n",
        "        \"free gift card click claim now winner announcement today\",\n",
        "        \"make money fast work from home easy income guaranteed\",\n",
        "        \"lose weight quick miracle pill doctor approved formula\",\n",
        "        \"viagra cheap online pharmacy prescription drugs discount prices\",\n",
        "        \"refinance mortgage lowest rates approved guaranteed bad credit ok\",\n",
        "        \"casino bonus free spins slots jackpot winner play now\",\n",
        "        \"investment opportunity guaranteed returns millionaire secrets revealed\",\n",
        "        \"credit card debt relief lawyer help bankruptcy avoid\",\n",
        "        \"insurance quote save hundreds dollars coverage protection family\",\n",
        "        \"dating singles nearby meet tonight local women interested\",\n",
        "        \"degree online university accredited diploma fast track program\"\n",
        "    ]\n",
        "\n",
        "    ham_messages = [\n",
        "        \"meeting scheduled for tomorrow afternoon conference room available\",\n",
        "        \"please review the attached document and provide feedback soon\",\n",
        "        \"lunch plans with friends this weekend restaurant reservation confirmed\",\n",
        "        \"project deadline extended until friday team meeting scheduled\",\n",
        "        \"thanks for your help with the presentation slides look great\",\n",
        "        \"reminder about dentist appointment tuesday morning don't forget\",\n",
        "        \"looking forward to vacation next month flight tickets booked\",\n",
        "        \"conference call rescheduled to thursday same time different day\",\n",
        "        \"birthday party invitation for saturday bring friends family welcome\",\n",
        "        \"grocery list includes milk bread eggs cheese vegetables fruits\",\n",
        "        \"weather forecast shows rain tomorrow umbrella might be needed\",\n",
        "        \"book recommendation mystery novel author writing style excellent\",\n",
        "        \"exercise routine includes running swimming cycling strength training variety\",\n",
        "        \"recipe ingredients chicken vegetables spices cooking instructions included\",\n",
        "        \"movie tickets purchased weekend plans entertainment family time\",\n",
        "        \"university course registration deadline approaching choose classes carefully\",\n",
        "        \"library books due next week return policy late fees\",\n",
        "        \"garden flowers blooming spring season beautiful colors nature\",\n",
        "        \"computer software update available security patches bug fixes\",\n",
        "        \"travel itinerary flight hotel rental car confirmation numbers\"\n",
        "    ]\n",
        "\n",
        "\n",
        "    import random\n",
        "    random.seed(42)\n",
        "\n",
        "\n",
        "    all_spam = []\n",
        "    all_ham = []\n",
        "\n",
        "    for _ in range(15):\n",
        "        for msg in spam_messages:\n",
        "            words = msg.split()\n",
        "\n",
        "            if len(words) > 5:\n",
        "                remove_count = random.randint(1, min(3, len(words)-3))\n",
        "                words = random.sample(words, len(words) - remove_count)\n",
        "            all_spam.append(' '.join(words))\n",
        "\n",
        "    for _ in range(15):\n",
        "        for msg in ham_messages:\n",
        "            words = msg.split()\n",
        "\n",
        "            if len(words) > 5:\n",
        "                remove_count = random.randint(1, min(3, len(words)-3))\n",
        "                words = random.sample(words, len(words) - remove_count)\n",
        "            all_ham.append(' '.join(words))\n",
        "\n",
        "    messages = all_spam + all_ham\n",
        "    labels = [1] * len(all_spam) + [0] * len(all_ham)\n",
        "\n",
        "    return messages, labels"
      ],
      "metadata": {
        "id": "L1SCaXbEXfJy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(y_true, y_pred, model_name, vectorizer_name):\n",
        "    \"\"\"\n",
        "    Evaluates a classification model on test data.\n",
        "\n",
        "    Returns a dictionary with metrics.\n",
        "    \"\"\"\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "\n",
        "    print(f\"\\nModel: {model_name} | Vectorizer: {vectorizer_name}\")\n",
        "    print(f\"Accuracy : {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall   : {recall:.4f}\")\n",
        "    print(f\"F1 Score : {f1:.4f}\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion_matrix(y_true, y_pred))\n",
        "\n",
        "    return {\n",
        "        'Model': model_name,\n",
        "        'Vectorizer': vectorizer_name,\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1': f1\n",
        "    }\n",
        "\n",
        "\n",
        "messages, labels = create_realistic_spam_dataset()\n",
        "\n",
        "X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
        "    messages, labels, test_size=0.3, random_state=42, stratify=labels\n",
        ")\n",
        "\n",
        "print(\"Dataset Information:\")\n",
        "print(f\"Training samples: {len(X_train_text)}\")\n",
        "print(f\"Testing samples: {len(X_test_text)}\")\n",
        "print(f\"Spam ratio: {np.mean(labels):.2f}\")\n",
        "\n",
        "results = []\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"LOGISTIC REGRESSION EXPERIMENT\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "reg_params = [0.01, 0.1, 1.0, 10.0]\n",
        "\n",
        "for vec_name, vectorizer in [('Count', CountVectorizer(stop_words='english', max_features=1000)),\n",
        "                           ('TF-IDF', TfidfVectorizer(stop_words='english', max_features=1000))]:\n",
        "    X_train_vec = vectorizer.fit_transform(X_train_text)\n",
        "    X_test_vec = vectorizer.transform(X_test_text)\n",
        "\n",
        "    for reg_param in reg_params:\n",
        "        lr = LogisticRegression(C=1/reg_param, random_state=42, max_iter=1000)\n",
        "        lr.fit(X_train_vec, y_train)\n",
        "        y_pred = lr.predict(X_test_vec)\n",
        "\n",
        "        result = evaluate_model(y_test, y_pred, 'Logistic Regression', vec_name)\n",
        "        result['Reg. λ'] = reg_param\n",
        "        results.append(result)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"NAIVE BAYES EXPERIMENT\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for vec_name, vectorizer in [('Count', CountVectorizer(stop_words='english', max_features=1000)),\n",
        "                           ('TF-IDF', TfidfVectorizer(stop_words='english', max_features=1000))]:\n",
        "    X_train_vec = vectorizer.fit_transform(X_train_text)\n",
        "    X_test_vec = vectorizer.transform(X_test_text)\n",
        "\n",
        "    X_train_dense = X_train_vec.toarray()\n",
        "    X_test_dense = X_test_vec.toarray()\n",
        "\n",
        "    nb = MultinomialNaiveBayes(alpha=1.0)\n",
        "    nb.fit(X_train_dense, y_train)\n",
        "\n",
        "    y_pred = nb.predict(X_test_dense)\n",
        "    y_pred_proba = nb.predict_proba(X_test_dense)\n",
        "\n",
        "    result = evaluate_model(y_test, y_pred, 'Naive Bayes', vec_name)\n",
        "    result['Reg. λ'] = '–'\n",
        "    results.append(result)\n",
        "\n",
        "    print(f\"\\nSample predictions with {vec_name} Vectorizer:\")\n",
        "    for i in range(min(5, len(y_test))):\n",
        "        actual = \"Spam\" if y_test[i] == 1 else \"Ham\"\n",
        "        predicted = \"Spam\" if y_pred[i] == 1 else \"Ham\"\n",
        "        prob_spam = y_pred_proba[i, 1]\n",
        "        print(f\"Actual: {actual:4}, Predicted: {predicted:4}, P(Spam): {prob_spam:.3f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"COMPARATIVE ANALYSIS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "column_order = ['Model', 'Vectorizer', 'Reg. λ', 'Accuracy', 'Precision', 'Recall', 'F1']\n",
        "results_df = results_df[column_order]\n",
        "\n",
        "print(\"\\nResults Summary Table:\")\n",
        "print(\"-\" * 90)\n",
        "results_display = results_df.copy()\n",
        "for col in ['Accuracy', 'Precision', 'Recall', 'F1']:\n",
        "    results_display[col] = results_display[col].apply(lambda x: f\"{x:.4f}\")\n",
        "print(results_display.to_string(index=False))\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"BEST PERFORMING MODELS\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "best_accuracy_idx = results_df['Accuracy'].idxmax()\n",
        "best_f1_idx = results_df['F1'].idxmax()\n",
        "\n",
        "best_accuracy = results_df.iloc[best_accuracy_idx]\n",
        "best_f1 = results_df.iloc[best_f1_idx]\n",
        "\n",
        "print(f\"\\nBest Accuracy: {best_accuracy['Model']} with {best_accuracy['Vectorizer']} vectorizer\")\n",
        "print(f\"Accuracy: {best_accuracy['Accuracy']:.4f}, F1: {best_accuracy['F1']:.4f}\")\n",
        "\n",
        "print(f\"\\nBest F1-Score: {best_f1['Model']} with {best_f1['Vectorizer']} vectorizer\")\n",
        "print(f\"Accuracy: {best_f1['Accuracy']:.4f}, F1: {best_f1['F1']:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcmOsuR3XlBN",
        "outputId": "852b31c3-4745-4b18-fcdd-f200ebcd6713"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Information:\n",
            "Training samples: 420\n",
            "Testing samples: 180\n",
            "Spam ratio: 0.50\n",
            "\n",
            "============================================================\n",
            "LOGISTIC REGRESSION EXPERIMENT\n",
            "============================================================\n",
            "\n",
            "Model: Logistic Regression | Vectorizer: Count\n",
            "Accuracy : 1.0000\n",
            "Precision: 1.0000\n",
            "Recall   : 1.0000\n",
            "F1 Score : 1.0000\n",
            "Confusion Matrix:\n",
            "[[90  0]\n",
            " [ 0 90]]\n",
            "\n",
            "Model: Logistic Regression | Vectorizer: Count\n",
            "Accuracy : 1.0000\n",
            "Precision: 1.0000\n",
            "Recall   : 1.0000\n",
            "F1 Score : 1.0000\n",
            "Confusion Matrix:\n",
            "[[90  0]\n",
            " [ 0 90]]\n",
            "\n",
            "Model: Logistic Regression | Vectorizer: Count\n",
            "Accuracy : 1.0000\n",
            "Precision: 1.0000\n",
            "Recall   : 1.0000\n",
            "F1 Score : 1.0000\n",
            "Confusion Matrix:\n",
            "[[90  0]\n",
            " [ 0 90]]\n",
            "\n",
            "Model: Logistic Regression | Vectorizer: Count\n",
            "Accuracy : 1.0000\n",
            "Precision: 1.0000\n",
            "Recall   : 1.0000\n",
            "F1 Score : 1.0000\n",
            "Confusion Matrix:\n",
            "[[90  0]\n",
            " [ 0 90]]\n",
            "\n",
            "Model: Logistic Regression | Vectorizer: TF-IDF\n",
            "Accuracy : 1.0000\n",
            "Precision: 1.0000\n",
            "Recall   : 1.0000\n",
            "F1 Score : 1.0000\n",
            "Confusion Matrix:\n",
            "[[90  0]\n",
            " [ 0 90]]\n",
            "\n",
            "Model: Logistic Regression | Vectorizer: TF-IDF\n",
            "Accuracy : 1.0000\n",
            "Precision: 1.0000\n",
            "Recall   : 1.0000\n",
            "F1 Score : 1.0000\n",
            "Confusion Matrix:\n",
            "[[90  0]\n",
            " [ 0 90]]\n",
            "\n",
            "Model: Logistic Regression | Vectorizer: TF-IDF\n",
            "Accuracy : 1.0000\n",
            "Precision: 1.0000\n",
            "Recall   : 1.0000\n",
            "F1 Score : 1.0000\n",
            "Confusion Matrix:\n",
            "[[90  0]\n",
            " [ 0 90]]\n",
            "\n",
            "Model: Logistic Regression | Vectorizer: TF-IDF\n",
            "Accuracy : 1.0000\n",
            "Precision: 1.0000\n",
            "Recall   : 1.0000\n",
            "F1 Score : 1.0000\n",
            "Confusion Matrix:\n",
            "[[90  0]\n",
            " [ 0 90]]\n",
            "\n",
            "============================================================\n",
            "NAIVE BAYES EXPERIMENT\n",
            "============================================================\n",
            "\n",
            "Model: Naive Bayes | Vectorizer: Count\n",
            "Accuracy : 1.0000\n",
            "Precision: 1.0000\n",
            "Recall   : 1.0000\n",
            "F1 Score : 1.0000\n",
            "Confusion Matrix:\n",
            "[[90  0]\n",
            " [ 0 90]]\n",
            "\n",
            "Sample predictions with Count Vectorizer:\n",
            "Actual: Spam, Predicted: Spam, P(Spam): 1.000\n",
            "Actual: Ham , Predicted: Ham , P(Spam): 0.000\n",
            "Actual: Spam, Predicted: Spam, P(Spam): 1.000\n",
            "Actual: Spam, Predicted: Spam, P(Spam): 1.000\n",
            "Actual: Ham , Predicted: Ham , P(Spam): 0.002\n",
            "\n",
            "Model: Naive Bayes | Vectorizer: TF-IDF\n",
            "Accuracy : 1.0000\n",
            "Precision: 1.0000\n",
            "Recall   : 1.0000\n",
            "F1 Score : 1.0000\n",
            "Confusion Matrix:\n",
            "[[90  0]\n",
            " [ 0 90]]\n",
            "\n",
            "Sample predictions with TF-IDF Vectorizer:\n",
            "Actual: Spam, Predicted: Spam, P(Spam): 0.984\n",
            "Actual: Ham , Predicted: Ham , P(Spam): 0.037\n",
            "Actual: Spam, Predicted: Spam, P(Spam): 0.987\n",
            "Actual: Spam, Predicted: Spam, P(Spam): 0.935\n",
            "Actual: Ham , Predicted: Ham , P(Spam): 0.095\n",
            "\n",
            "============================================================\n",
            "COMPARATIVE ANALYSIS\n",
            "============================================================\n",
            "\n",
            "Results Summary Table:\n",
            "------------------------------------------------------------------------------------------\n",
            "              Model Vectorizer Reg. λ Accuracy Precision Recall     F1\n",
            "Logistic Regression      Count   0.01   1.0000    1.0000 1.0000 1.0000\n",
            "Logistic Regression      Count    0.1   1.0000    1.0000 1.0000 1.0000\n",
            "Logistic Regression      Count    1.0   1.0000    1.0000 1.0000 1.0000\n",
            "Logistic Regression      Count   10.0   1.0000    1.0000 1.0000 1.0000\n",
            "Logistic Regression     TF-IDF   0.01   1.0000    1.0000 1.0000 1.0000\n",
            "Logistic Regression     TF-IDF    0.1   1.0000    1.0000 1.0000 1.0000\n",
            "Logistic Regression     TF-IDF    1.0   1.0000    1.0000 1.0000 1.0000\n",
            "Logistic Regression     TF-IDF   10.0   1.0000    1.0000 1.0000 1.0000\n",
            "        Naive Bayes      Count      –   1.0000    1.0000 1.0000 1.0000\n",
            "        Naive Bayes     TF-IDF      –   1.0000    1.0000 1.0000 1.0000\n",
            "\n",
            "==================================================\n",
            "BEST PERFORMING MODELS\n",
            "==================================================\n",
            "\n",
            "Best Accuracy: Logistic Regression with Count vectorizer\n",
            "Accuracy: 1.0000, F1: 1.0000\n",
            "\n",
            "Best F1-Score: Logistic Regression with Count vectorizer\n",
            "Accuracy: 1.0000, F1: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"CONFUSION MATRICES\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "count_vec = CountVectorizer(stop_words='english', max_features=1000)\n",
        "X_train_count = count_vec.fit_transform(X_train_text).toarray()\n",
        "X_test_count = count_vec.transform(X_test_text).toarray()\n",
        "\n",
        "nb_count = MultinomialNaiveBayes(alpha=1.0)\n",
        "nb_count.fit(X_train_count, y_train)\n",
        "y_pred_nb_count = nb_count.predict(X_test_count)\n",
        "\n",
        "print(\"\\nConfusion Matrix - Naive Bayes with Count Vectorizer:\")\n",
        "cm_nb = confusion_matrix(y_test, y_pred_nb_count)\n",
        "print(f\"True Negatives (Ham predicted as Ham): {cm_nb[0,0]}\")\n",
        "print(f\"False Positives (Ham predicted as Spam): {cm_nb[0,1]}\")\n",
        "print(f\"False Negatives (Spam predicted as Ham): {cm_nb[1,0]}\")\n",
        "print(f\"True Positives (Spam predicted as Spam): {cm_nb[1,1]}\")\n",
        "\n",
        "tfidf_vec = TfidfVectorizer(stop_words='english', max_features=1000)\n",
        "X_train_tfidf = tfidf_vec.fit_transform(X_train_text)\n",
        "X_test_tfidf = tfidf_vec.transform(X_test_text)\n",
        "\n",
        "lr_best = LogisticRegression(C=10, random_state=42, max_iter=1000)\n",
        "lr_best.fit(X_train_tfidf, y_train)\n",
        "y_pred_lr_tfidf = lr_best.predict(X_test_tfidf)\n",
        "\n",
        "print(\"\\nConfusion Matrix - Logistic Regression with TF-IDF:\")\n",
        "cm_lr = confusion_matrix(y_test, y_pred_lr_tfidf)\n",
        "print(f\"True Negatives (Ham predicted as Ham): {cm_lr[0,0]}\")\n",
        "print(f\"False Positives (Ham predicted as Spam): {cm_lr[0,1]}\")\n",
        "print(f\"False Negatives (Spam predicted as Ham): {cm_lr[1,0]}\")\n",
        "print(f\"True Positives (Spam predicted as Spam): {cm_lr[1,1]}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ALGORITHM IMPLEMENTATION DETAILS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\nNaive Bayes Formula Implementation:\")\n",
        "print(\"P(spam|document) ∝ P(spam) × ∏ P(word|spam)\")\n",
        "print(\"With Laplace smoothing: P(word|class) = (count + α) / (total + α × vocab_size)\")\n",
        "print(f\"Alpha (smoothing parameter): {nb_count.alpha}\")\n",
        "\n",
        "print(f\"\\nClass Priors:\")\n",
        "for class_label, prior in nb_count.class_priors.items():\n",
        "    class_name = \"Ham\" if class_label == 0 else \"Spam\"\n",
        "    print(f\"P({class_name}) = {prior:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PERFORMANCE SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "nb_results = results_df[results_df['Model'] == 'Naive Bayes']\n",
        "lr_results = results_df[results_df['Model'] == 'Logistic Regression']\n",
        "\n",
        "print(f\"Naive Bayes - Average Performance:\")\n",
        "print(f\"  Accuracy: {nb_results['Accuracy'].mean():.4f}\")\n",
        "print(f\"  F1-Score: {nb_results['F1'].mean():.4f}\")\n",
        "\n",
        "print(f\"\\nLogistic Regression - Average Performance:\")\n",
        "print(f\"  Accuracy: {lr_results['Accuracy'].mean():.4f}\")\n",
        "print(f\"  F1-Score: {lr_results['F1'].mean():.4f}\")\n",
        "\n",
        "print(f\"\\nVectorization Impact:\")\n",
        "count_results = results_df[results_df['Vectorizer'] == 'Count']\n",
        "tfidf_results = results_df[results_df['Vectorizer'] == 'TF-IDF']\n",
        "\n",
        "print(f\"Count Vectorizer - Average F1: {count_results['F1'].mean():.4f}\")\n",
        "print(f\"TF-IDF Vectorizer - Average F1: {tfidf_results['F1'].mean():.4f}\")\n",
        "\n",
        "if tfidf_results['F1'].mean() > count_results['F1'].mean():\n",
        "    print(\"→ TF-IDF shows better performance overall\")\n",
        "else:\n",
        "    print(\"→ Count vectorizer shows better performance overall\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBrChoSxXpCX",
        "outputId": "6f6aa44f-e6e8-45e3-fc30-4c5f6db33eaa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "CONFUSION MATRICES\n",
            "==================================================\n",
            "\n",
            "Confusion Matrix - Naive Bayes with Count Vectorizer:\n",
            "True Negatives (Ham predicted as Ham): 90\n",
            "False Positives (Ham predicted as Spam): 0\n",
            "False Negatives (Spam predicted as Ham): 0\n",
            "True Positives (Spam predicted as Spam): 90\n",
            "\n",
            "Confusion Matrix - Logistic Regression with TF-IDF:\n",
            "True Negatives (Ham predicted as Ham): 90\n",
            "False Positives (Ham predicted as Spam): 0\n",
            "False Negatives (Spam predicted as Ham): 0\n",
            "True Positives (Spam predicted as Spam): 90\n",
            "\n",
            "============================================================\n",
            "ALGORITHM IMPLEMENTATION DETAILS\n",
            "============================================================\n",
            "\n",
            "Naive Bayes Formula Implementation:\n",
            "P(spam|document) ∝ P(spam) × ∏ P(word|spam)\n",
            "With Laplace smoothing: P(word|class) = (count + α) / (total + α × vocab_size)\n",
            "Alpha (smoothing parameter): 1.0\n",
            "\n",
            "Class Priors:\n",
            "P(Ham) = 0.5000\n",
            "P(Spam) = 0.5000\n",
            "\n",
            "============================================================\n",
            "PERFORMANCE SUMMARY\n",
            "============================================================\n",
            "Naive Bayes - Average Performance:\n",
            "  Accuracy: 1.0000\n",
            "  F1-Score: 1.0000\n",
            "\n",
            "Logistic Regression - Average Performance:\n",
            "  Accuracy: 1.0000\n",
            "  F1-Score: 1.0000\n",
            "\n",
            "Vectorization Impact:\n",
            "Count Vectorizer - Average F1: 1.0000\n",
            "TF-IDF Vectorizer - Average F1: 1.0000\n",
            "→ Count vectorizer shows better performance overall\n"
          ]
        }
      ]
    }
  ]
}